{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Experiments"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kitti_t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/home.dokt/vacekpa2/pcflow/pipeline/sceneflow.py\", line 446, in <module>\n",
      "    Experiment.optimize_sceneflow()\n",
      "  File \"/mnt/home.dokt/vacekpa2/pcflow/pipeline/sceneflow.py\", line 290, in optimize_sceneflow\n",
      "    pred_dict = solver(pc1, pc2, gt_flow, self.model, self.Loss_Function, self.args)\n",
      "  File \"/mnt/home.dokt/vacekpa2/pcflow/pipeline/sceneflow.py\", line 135, in solver\n",
      "    Loss_Function.update(pc1, pc2)\n",
      "  File \"/home.dokt/vacekpa2/pcflow/loss/flow.py\", line 521, in update\n",
      "    self.VAChamfer_loss = VAChamferLoss(pc2, **self.kwargs)\n",
      "  File \"/home.dokt/vacekpa2/pcflow/loss/flow.py\", line 400, in __init__\n",
      "    self.Visibility = VisibilityScene(dataset=self.kwargs['dataset'], pc_scene=pc2)\n",
      "  File \"/home.dokt/vacekpa2/pcflow/data/range_image.py\", line 315, in __init__\n",
      "    self.depth_image = self.calculate_depth_image()\n",
      "  File \"/home.dokt/vacekpa2/pcflow/data/range_image.py\", line 389, in calculate_depth_image\n",
      "    self.depth_image = - torch.ones((self.H, self.W), dtype=torch.float, device=self.pc_scene.device)\n",
      "RuntimeError: CUDA error: device-side assert triggered\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "/tmp/eb-build/PyTorch/2.0.0/foss-2022a-CUDA-11.7.0/pytorch-v2.0.0/aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [0,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/tmp/eb-build/PyTorch/2.0.0/foss-2022a-CUDA-11.7.0/pytorch-v2.0.0/aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [1,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/tmp/eb-build/PyTorch/2.0.0/foss-2022a-CUDA-11.7.0/pytorch-v2.0.0/aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [2,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/tmp/eb-build/PyTorch/2.0.0/foss-2022a-CUDA-11.7.0/pytorch-v2.0.0/aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [3,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/tmp/eb-build/PyTorch/2.0.0/foss-2022a-CUDA-11.7.0/pytorch-v2.0.0/aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [4,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/tmp/eb-build/PyTorch/2.0.0/foss-2022a-CUDA-11.7.0/pytorch-v2.0.0/aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [5,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import torch\n",
    "from configs.models import SCOOP_cfg, NeuralPrior_cfg\n",
    "from data.gpu_utils import get_free_gpu_indices\n",
    "from pipeline.run_utils import run_experiment\n",
    "\n",
    "\n",
    "# load cfg list from csv later? or just permute variables\n",
    "cfg_list = [#{**SCOOP_cfg, 'affiliation' : 'baseline', 'smooth_weight' : 1},\n",
    "            # {**NeuralPrior_cfg, 'affiliation' : 'baseline'},\n",
    "\n",
    "            # {**SCOOP_cfg, 'affiliation' : 'ours', 'sm_normals_K' : 8, 'lr' : 0.08},\n",
    "            # {**SCOOP_cfg, 'affiliation' : 'ours', 'free_weight' : 1},\n",
    "            # {**SCOOP_cfg, 'affiliation' : 'ours', 'forward_weight' : 1, 'pc2_smooth' : 1},\n",
    "            # {**SCOOP_cfg, 'affiliation' : 'ours', 'forward_weight' : 10, 'pc2_smooth' : 1},\n",
    "            # ctrl+d to clone\n",
    "\n",
    "            # {**NeuralPrior_cfg, 'affiliation' : 'ours', 'sm_normals_K' : 8, 'K' : 32, 'smooth_weight' : 10., 'forward_weight' : 0, 'pc2_smooth' : 1},\n",
    "            # {**NeuralPrior_cfg, 'affiliation' : 'ours', 'sm_normals_K' : 8, 'K' : 32, 'smooth_weight' : 3., 'forward_weight' : 1, 'pc2_smooth' : 1},\n",
    "            # {**NeuralPrior_cfg, 'affiliation' : 'ours', 'sm_normals_K' : 8, 'K' : 32, 'smooth_weight' : 1., 'forward_weight' : 1, 'pc2_smooth' : 1},\n",
    "            # {**NeuralPrior_cfg, 'affiliation' : 'ours', 'sm_normals_K' : 8, 'K' : 32, 'smooth_weight' : 1., 'forward_weight' : 1, 'pc2_smooth' : False},\n",
    "            {**NeuralPrior_cfg, 'affiliation' : 'ours', 'sm_normals_K' : 5, 'K' : 4, 'smooth_weight' : 1., 'forward_weight' : 1, 'free_weight' : 1, 'pc2_smooth' : 1, 'VA' : 1},\n",
    "\n",
    "\n",
    "            # {**SCOOP_cfg, 'affiliation' : 'ours', 'sm_normals_K' : 8, 'forward_weight' : 1, 'pc2_smooth' : 1, 'lr' : 0.08},\n",
    "            ]\n",
    "\n",
    "import subprocess\n",
    "DETACH = 0\n",
    "# tohle cele do subprocessu ve funkci potom #\n",
    "\n",
    "for cfg in cfg_list:\n",
    "\n",
    "    while len(get_free_gpu_indices()) == 0:\n",
    "        print('waiting for gpu')\n",
    "        time.sleep(20)\n",
    "\n",
    "\n",
    "    # for dataset in ['kitti_o', 'kitti_t', 'argoverse', 'nuscenes', 'waymo']:\n",
    "    for dataset in ['kitti_t']:\n",
    "\n",
    "        cfg['dataset'] = dataset\n",
    "        cfg['iters'] = 10\n",
    "        # cfg['lr'] = 0.008\n",
    "        cfg['dev'] = 1\n",
    "        print(dataset)\n",
    "        run_experiment(cfg, DETACH=DETACH)\n",
    "\n",
    "    # time.sleep(5)\n",
    "\n",
    "    # break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T13:05:57.029140453Z",
     "start_time": "2023-07-18T13:05:50.013803421Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # Visualize\n",
    "from vis.deprecated_vis import *\n",
    "from data.PATHS import TMP_VIS_PATH\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "\n",
    "last_exp = sorted(glob.glob(f'{os.path.expanduser(\"~\")}/experiments/SCOOP/*'))[-1]\n",
    "data = np.load(f'{last_exp}/inference/000000.npz', allow_pickle=True)\n",
    "pc1 = data['pc1']\n",
    "pc2 = data['pc2']\n",
    "est_flow1 = data['est_flow']\n",
    "\n",
    "# plot epe and loss\n",
    "epe_all = data['epe_all']\n",
    "loss_all = data['loss_all']\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig, axes = plt.subplots(ncols=2)\n",
    "\n",
    "axes[0].plot(epe_all, 'r--')\n",
    "axes[1].plot(loss_all, 'b--')\n",
    "axes[0].set_title('EPE per iter')\n",
    "axes[1].set_title('Loss per iter')\n",
    "\n",
    "\n",
    "axes[0].set_xlabel('iter')\n",
    "axes[1].set_xlabel('iter')\n",
    "axes[0].set_ylabel('EPE')\n",
    "axes[1].set_ylabel('loss')\n",
    "axes[0].legend(['EPE'])\n",
    "axes[1].legend(['Loss'])\n",
    "axes[0].grid(True)\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.savefig(f'{TMP_VIS_PATH}/epe_loss.png')\n",
    "plt.close()\n",
    "# visualize_flow3d(pc1, pc2, est_flow1)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# notes\n",
    "- SCOOP wont generalize to other real world datasets (Cross-dataset evaluation) - performance on argoverse is bad, retraining?\n",
    "    - \"It extracts discriminative features, which transfer well across the FT3Do and KITTIo datasets, and enables to compute the correspondence-based flow between the point clouds\"\n",
    "    - We dont have advantage in that, but this kinda justifies the results on argoverse without fine-tunning?\n",
    "    - KittiSF is bijection, that is why it works very good in SCOOP\n",
    "- https://arxiv.org/pdf/2305.02528.pdf cite baseline\n",
    "- Pouceni z reimplementace\n",
    "    - Asi to fakt chce delat krok po kroku uz odzacatku? Tim mysleno testovat vsechno krok po kroku kdyz se prevezmou funkce\n",
    "    - Izolovat (rozumet tem krokum, jinak je proste nedelat, opravdu nedelat)\n",
    "    - Skvely je mit ten framework udelany podle toho, co opravdu clovek delat\n",
    "    - Nejlepsi je mit vsechno v jednom editoru viz. poustet pre python subprocessy, jinak prepinani zpomaluje a nici to framework workflow\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Compare experiments, # Udelat cross experiment vizualizaci\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from data.PATHS import TMP_VIS_PATH\n",
    "\n",
    "exp_name = \"NeuralPrior\"\n",
    "exp_dir = f'{os.path.expanduser(\"~\")}/experiments/{exp_name}'\n",
    "runs = sorted(glob.glob(f'{exp_dir}/*'))\n",
    "\n",
    "# plot?\n",
    "\n",
    "metric_all = []\n",
    "fig, axes = plt.subplots(1, 2)#, figsize=(10, 5))\n",
    "\n",
    "for run in runs:\n",
    "\n",
    "    if os.path.exists(f'{run}/metric.csv') == False:\n",
    "        continue\n",
    "\n",
    "    metric = pd.read_csv(f'{run}/metric.csv', index_col=0, header=None).transpose()\n",
    "    args = pd.read_csv(f'{run}/args.csv', index_col=0, header=None).transpose()\n",
    "\n",
    "\n",
    "    # Skip tryouts\n",
    "    dev = int(args['dev'].values[0])\n",
    "\n",
    "    if dev == 1:\n",
    "        continue\n",
    "\n",
    "    aff = args['affiliation'].values[0]\n",
    "    epe = metric['EPE3D'].values[0]\n",
    "\n",
    "    avg_solver_time = metric['avg_solver_time'].values[0]\n",
    "\n",
    "    if aff == 'baseline':\n",
    "        axes[0].plot(avg_solver_time, epe, 'b*', markersize=10)\n",
    "\n",
    "    if aff == 'ours':\n",
    "        axes[0].plot(avg_solver_time, epe, 'g*', markersize=10)\n",
    "\n",
    "\n",
    "    print_metric = metric\n",
    "    print_metric['aff'] = aff\n",
    "    print_metric['free'] = args.free_weight\n",
    "    print_metric['forward'] = args.forward_weight\n",
    "    print_metric['pc2_smooth'] = args.pc2_smooth\n",
    "    print_metric['free'] = args.free_weight\n",
    "\n",
    "    metric_all.append(print_metric)\n",
    "\n",
    "df = pd.concat(metric_all, ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "axes[0].set_xlabel('Average Solver Time Per Frame [s]')\n",
    "axes[0].set_ylabel('EPE [m]')\n",
    "\n",
    "axes[0].set_title('Performance on KITTI-SF')\n",
    "axes[0].legend(['baseline', 'ours'])\n",
    "axes[0].grid(True)\n",
    "\n",
    "\n",
    "#create pandas DataFrame\n",
    "\n",
    "#create table\n",
    "# table = plt.table(cellText=df.values, colLabels=df.columns, loc='center')\n",
    "plt.savefig(f'{TMP_VIS_PATH}/kittisf.png')\n",
    "plt.close()\n",
    "\n",
    "df\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "res_path = sorted(glob.glob(os.path.expanduser(\"~\") + '/experiments/SCOOP/2023-07-13-12-55-18-642/inference/*'))\n",
    "# kitti_t = [file for file in sorted(glob.glob(os.path.expanduser(\"~\") + '/pcflow/models/SCOOP/pretrained_models/kitti_v_100_examples/pc_res/*.npz'))]\n",
    "# kitti_t = [int(os.path.basename(file).split('_')[0]) for file in sorted(glob.glob(os.path.expanduser(\"~\") + '/pcflow/models/SCOOP/pretrained_models/kitti_v_100_examples/pc_res/*.npz'))]\n",
    "\n",
    "kitti_t_files = sorted(glob.glob(os.path.expanduser(\"~\") + '/pcflow/models/SCOOP/pretrained_models/kitti_v_100_examples/pc_res/*.npz'))\n",
    "\n",
    "epe_list = []\n",
    "# visualize one frame\n",
    "for idx in range(len(kitti_t_files)):\n",
    "\n",
    "    # My\n",
    "    # data = np.load(f'{res_path[idx]}', allow_pickle=True)\n",
    "    # epe = data['EPE3D']\n",
    "\n",
    "    # Former\n",
    "    data = np.load(f'{kitti_t_files[idx]}', allow_pickle=True)\n",
    "    pred_flow = data['est_flow_for_pc1']\n",
    "    gt_flow = data['gt_flow_for_pc1']\n",
    "    epe = np.linalg.norm(pred_flow - gt_flow, axis=1).mean()\n",
    "\n",
    "    # if idx == 43:\n",
    "    # print(data['pc1'].shape, data['pc2'].shape)\n",
    "\n",
    "\n",
    "    epe_list.append(epe)\n",
    "\n",
    "    # print(os.path.basename(res_path[idx]), epe)\n",
    "\n",
    "    # to get pitch field of view\n",
    "    # pc2 = data['pc2']\n",
    "    # pitch = np.arcsin(pc2[:, 1] / np.linalg.norm(pc2, axis=1))\n",
    "    # print(pitch.max() * 180 / np.pi, pitch.min() * 180 / np.pi)\n",
    "\n",
    "plt.plot(epe_list, 'b*')\n",
    "plt.title(f'EPE on KITTI-SF --- {np.array(epe_list).mean():.5f}m')\n",
    "plt.xlabel('Frame [-]')\n",
    "plt.ylabel('EPE [m]')\n",
    "\n",
    "plt.savefig(f'{TMP_VIS_PATH}/epe.png')\n",
    "plt.close()\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "### Make configs\n",
    "\n",
    "permute_cfg = {'model': ['NeuralPrior', 'SCOOP'],\n",
    "               'sm_normals_K': [0, 3, 5, 8, 12],\n",
    "               'FSM':  [0, 1, 2, 4, 10],\n",
    "               'pc2_smooth': [0, 1],\n",
    "               'K': [0, 4, 6, 8, 32],\n",
    "               'Free_weight': [0, 1, 2, 5],\n",
    "               'VA_SM': [0, 1],\n",
    "               'lr': [0.2, 0.08, 0.008, 0.001, 0.003],\n",
    "               'dataset': ['kitti_t', 'kitti_o', 'argoverse', 'nuscenes', 'waymo'],\n",
    "               'max_radius' : [2],\n",
    "               'run': [0]}  # use 3 runs, each server one\n",
    "\n",
    "\n",
    "# permute all possible combinations of variables above\n",
    "\n",
    "index = permute_cfg.keys()\n",
    "combinations = list(itertools.product(*permute_cfg.values()))\n",
    "\n",
    "df = pd.DataFrame(combinations, columns=index)\n",
    "\n",
    "valid_cfg_list = []\n",
    "\n",
    "# leave out some configs\n",
    "for i in range(len(combinations)):\n",
    "\n",
    "    c = df.iloc[i]\n",
    "\n",
    "    ##### Kittisf\n",
    "    if c['dataset'].startswith('kitti'):\n",
    "\n",
    "        if c['K'] != 32: continue\n",
    "\n",
    "    ##### Lidar\n",
    "    if not c['dataset'].startswith('kitti'):\n",
    "\n",
    "        if c['K'] > 8: continue\n",
    "        if c['sm_normals_K'] > 5: continue\n",
    "\n",
    "    ##### Models\n",
    "    if c['model'] == \"SCOOP\":\n",
    "\n",
    "        if c['K'] != 32: continue\n",
    "        if c['lr'] != 0.2: continue\n",
    "        if c['dataset'] in ['argoverse', 'nuscenes', 'waymo']: continue\n",
    "\n",
    "    if c['model'] == 'NeuralPrior':\n",
    "\n",
    "        if c['dataset'] in ['kitti_o']: continue\n",
    "        if c['lr'] != 0.001 and c['dataset'] == 'kitti_t': continue\n",
    "        if c['lr'] != 0.003 and c['dataset'] in ['argoverse', 'waymo', 'nuscenes']: continue\n",
    "\n",
    "\n",
    "    ##### General\n",
    "    if c['FSM'] == 0 and c['pc2_smooth'] == 1: continue\n",
    "    if c['K'] == 0 and (c['FSM'] > 0 or c['VA_SM'] > 0): continue\n",
    "\n",
    "\n",
    "    # you can add default configs\n",
    "\n",
    "    valid_cfg_list.append(c.to_dict())\n",
    "\n",
    "print(len(valid_cfg_list))\n",
    "nbr_gpu = 5\n",
    "experiment_time = 10 / 60 # hours\n",
    "gpu_time = len(valid_cfg_list) * experiment_time\n",
    "\n",
    "print(f\"Runs: {len(valid_cfg_list)} ---> GPU time: {gpu_time:.1f} hours ---> {gpu_time / nbr_gpu / 24:.1f} days\")\n",
    "\n",
    "final_df = pd.DataFrame(valid_cfg_list, columns=index)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Top down view example of NN connections\n",
    "KNN = nn_ind[0]\n",
    "start_arrows = pc2[0][KNN].reshape(-1,3)\n",
    "\n",
    "# NN connections\n",
    "residuals_KNN = (pc2[0].unsqueeze(1) - pc2[0][KNN]).reshape(-1,3)\n",
    "residuals_VA_KNN = (pc2[0].unsqueeze(1) - pc2[0][VA_KNN]).reshape(-1,3)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from data.PATHS import TMP_VIS_PATH\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(10,5))\n",
    "ax[0].plot(start_arrows[:,0].cpu(), start_arrows[:,1].cpu(), 'bo', alpha=0.15, markersize=0.1)\n",
    "ax[1].plot(start_arrows[:,0].cpu(), start_arrows[:,1].cpu(), 'bo', alpha=0.15, markersize=0.1)\n",
    "\n",
    "ax[0].quiver(start_arrows[:,0].cpu(), start_arrows[:,1].cpu(), residuals_KNN[:,0].cpu(), residuals_KNN[:,1].cpu(), color='r', scale_units='xy')\n",
    "ax[1].quiver(start_arrows[:,0].cpu(), start_arrows[:,1].cpu(), residuals_VA_KNN[:,0].cpu(), residuals_VA_KNN[:,1].cpu(), color='r', scale_units='xy')\n",
    "\n",
    "ax[0].axis('equal')\n",
    "ax[1].axis('equal')\n",
    "\n",
    "plt.savefig(f'{TMP_VIS_PATH}/{dataset_type}_range.png')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# Function to reassign depth to point clouds - it is somewhere\n",
    "# produce same outputs so you dont have to recalculate them in each experiment\n",
    "from data.range_image import *\n",
    "from data.params.kittisf import P_rect\n",
    "\n",
    "from vis.deprecated_vis import *\n",
    "import numpy as np\n",
    "from data.PATHS import TMP_VIS_PATH\n",
    "\n",
    "\n",
    "depth_image = np.load(\"/home.dokt/vacekpa2/data/kittisf/all_data_format/000000.npz\")['depth1']\n",
    "\n",
    "\n",
    "orig_pc2 = np.load(\"/home.dokt/vacekpa2/data/kittisf/all_data_format/000000.npz\")['pc1']\n",
    "\n",
    "depth_image = torch.from_numpy(depth_image)\n",
    "orig_pc2 = torch.from_numpy(orig_pc2)\n",
    "# print(orig_pc2.shape)\n",
    "# recon_pc = pixel2xyz(depth_image, P_rect)\n",
    "# recon_pc = recon_pc.reshape(-1,3)\n",
    "recon_pc = orig_pc2\n",
    "# new_depth_image, px, py = xyz2pixel(recon_pc[:], P_rect, depth_image.shape[0], depth_image.shape[1])\n",
    "\n",
    "plt.close()\n",
    "plt.clf()\n",
    "dataset_type = 'kitti_t'\n",
    "\n",
    "Visibility = VisibilityModule(dataset = dataset_type)\n",
    "\n",
    "\n",
    "# new_depth_image, px, py, inside = Visibility.generate_range_coors(recon_pc[None, :, :])\n",
    "# from data.range_image import xyz2pixel\n",
    "# new_depth_image, px, py, mask = xyz2pixel(recon_pc[:, :], P_rect, depth_image.shape[0], depth_image.shape[1])\n",
    "\n",
    "recon_pc = recon_pc# + torch.rand(recon_pc.shape)\n",
    "pc = recon_pc\n",
    "height, width = depth_image.shape[0], depth_image.shape[1]\n",
    "x = - pc[:,0]\n",
    "y = - pc[:,1]\n",
    "z = pc[:,2]\n",
    "\n",
    "depth = z   # in this case\n",
    "# depth = pc.norm(dim=-1)   # in this case\n",
    "focal_length_pixel = P_rect[0, 0]\n",
    "# height, width = depth_image.shape[:2]\n",
    "\n",
    "const_x = P_rect[0, 2] * depth + P_rect[0, 3]\n",
    "const_y = P_rect[1, 2] * depth + P_rect[1, 3]\n",
    "\n",
    "# const_x = P_rect[0, 2]\n",
    "# const_y = P_rect[1, 2]\n",
    "\n",
    "px = (x * focal_length_pixel + const_x) / (depth + P_rect[2, 3])\n",
    "py = (y * focal_length_pixel + const_y) / (depth + P_rect[2, 3])\n",
    "\n",
    "# px = (x / z) * focal_length_pixel + const_x\n",
    "# py = (y / z) * focal_length_pixel + const_y\n",
    "\n",
    "# drop outside image points\n",
    "mask = (px > 0) & (py > 0) & (px < width) & (py < height)\n",
    "\n",
    "new_depth_image = - torch.ones((height, width), dtype=torch.float, device=pc.device)\n",
    "new_depth_image[py[mask].to(int), px[mask].to(int)] = depth[mask]\n",
    "\n",
    "\n",
    "\n",
    "# visualize_points3D(recon_pc, mask)\n",
    "fig, ax = plt.subplots(3,1)\n",
    "ax[0].imshow(depth_image), ax[0].set_title('Orig depth')\n",
    "ax[1].imshow(new_depth_image), ax[1].set_title('Recon depth')\n",
    "ax[2].imshow(depth_image - new_depth_image, interpolation='none'), ax[2].set_title('Diff')\n",
    "\n",
    "plt.savefig(f'{TMP_VIS_PATH}/{dataset_type}_depth.png')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T11:51:05.486703429Z",
     "start_time": "2023-07-18T11:51:04.969611545Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([375, 1242])\n"
     ]
    }
   ],
   "source": [
    "from data.range_image import VisibilityScene\n",
    "import numpy as np\n",
    "import torch\n",
    "from data.PATHS import TMP_VIS_PATH\n",
    "H = 375\n",
    "W = 1242\n",
    "\n",
    "\n",
    "\n",
    "pc = np.load(\"/home.dokt/vacekpa2/data/kittisf/all_data_format/000000.npz\")['pc2']\n",
    "pc = pc[:, [2, 0, 1]]\n",
    "pc = torch.from_numpy(pc)\n",
    "# pc[:, 1] = - pc[:, 1]\n",
    "# pc[:, 2] = - pc[:, 2]\n",
    "\n",
    "# visualize_points3D(pc, pc[:,2])\n",
    "\n",
    "DepthScene = VisibilityScene(dataset='kitti_t',pc_scene=pc)\n",
    "\n",
    "\n",
    "# todo from min\n",
    "depth_image = DepthScene.depth_image\n",
    "\n",
    "# flow\n",
    "flow = pc.clone() #+ torch.rand(pc.shape) * 0.1 - 0.05\n",
    "\n",
    "print(depth_image.shape)\n",
    "visible_depth = DepthScene.assign_depth_to_flow(flow)\n",
    "\n",
    "flow_depth = flow.norm(dim=1)\n",
    "\n",
    "from vis.deprecated_vis import visualize_points3D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "visualize_points3D(flow, visible_depth > flow_depth)\n",
    "\n",
    "\n",
    "plt.close()\n",
    "plt.clf()\n",
    "plt.cla()\n",
    "fig, ax = plt.subplots(3,1)\n",
    "\n",
    "ax[0].imshow(depth_image), ax[0].set_title('Orig depth')\n",
    "plt.savefig(f'{TMP_VIS_PATH}/test_depth.png')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T13:08:28.755768398Z",
     "start_time": "2023-07-18T13:08:28.255716266Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T12:27:27.332095999Z",
     "start_time": "2023-07-18T12:27:27.288220053Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
