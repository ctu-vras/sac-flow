{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-28T11:46:20.180320881Z",
     "start_time": "2023-08-28T11:46:18.017406069Z"
    }
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "from vis.deprecated_vis import *\n",
    "\n",
    "from data.PATHS import DATA_PATH\n",
    "\n",
    "data_path = f'{DATA_PATH}/valeo_emre/'\n",
    "npz_file = glob.glob(f'{data_path}/*.npz')[3]\n",
    "data_file = np.load(npz_file, allow_pickle=True)\n",
    "\n",
    "odom_list = data_file['odom_list']\n",
    "scan_list = data_file['scan_list']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 2/73 [00:00<00:02, 32.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.73154550e-02  9.99847487e-01 -2.27558769e-03  2.09577000e+01]\n",
      " [-9.99849706e-01  1.73134441e-02 -9.00436482e-04 -7.26474000e+00]\n",
      " [-8.60900894e-04  2.29083715e-03  9.99997005e-01 -9.35357000e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "[[ 1.65055695e-02  9.99861159e-01 -2.28647076e-03  2.09600000e+01]\n",
      " [-9.99863306e-01  1.65033067e-02 -1.00503472e-03 -7.30740000e+00]\n",
      " [-9.67160849e-04  2.30274689e-03  9.99996881e-01 -9.17382000e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "[[ 1.60356313e-02  9.99869052e-01 -2.17665248e-03  2.09604000e+01]\n",
      " [-9.99870914e-01  1.60333919e-02 -1.04240545e-03 -7.33923000e+00]\n",
      " [-1.00736983e-03  2.19308713e-03  9.99997088e-01 -9.10506000e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# processing\n",
    "from tqdm import tqdm\n",
    "data_npz = {}\n",
    "os.makedirs(npz_file[:-4], exist_ok=True)\n",
    "\n",
    "pcl_list = []\n",
    "global_list = []\n",
    "for i in tqdm(range(180, len(scan_list) - 1)):\n",
    "    \n",
    "    pc1 = np.stack((scan_list[i][0]['x'],\n",
    "        scan_list[i][0]['y'],\n",
    "        scan_list[i][0]['z'],\n",
    "        scan_list[i][0]['i'],\n",
    "        scan_list[i][0]['layer_id'])).T\n",
    "    \n",
    "    pc2 = np.stack((scan_list[i+1][0]['x'],\n",
    "        scan_list[i+1][0]['y'],\n",
    "        scan_list[i+1][0]['z'],\n",
    "        scan_list[i+1][0]['i'],\n",
    "        scan_list[i+1][0]['layer_id'])).T  \n",
    "    \n",
    "    lidar1 = scan_list[i][0]['lidar'] == 0\n",
    "    lidar2 = scan_list[i+1][0]['lidar'] == 0\n",
    "    \n",
    "    pose1 = odom_list['transformation'][i]\n",
    "    pose2 = odom_list['transformation'][i+1]\n",
    "    \n",
    "    \n",
    "    \n",
    "    gt_flow = - np.ones((pc1.shape[0], 3))\n",
    "    data_npz = {\n",
    "        'pc1': pc1[lidar1,:3],\n",
    "        'pc2': pc2[lidar2,:3],\n",
    "        'flow' : gt_flow,\n",
    "        'pose1': pose1,\n",
    "        'pose2': pose2\n",
    "    }\n",
    "    \n",
    "    pcl_list.append(np.insert(pc1.copy()[lidar1], 3, i, axis=1))\n",
    "    global_list.append((np.insert(pc1.copy()[lidar1], 3, 1, axis=1)[:,:4] @ pose1.T)[:,:3])\n",
    "    np.savez(f'{data_path}/{os.path.basename(npz_file)[:-4]}/{i:06d}.npz', **data_npz)\n",
    "    \n",
    "    print(pose1)\n",
    "    \n",
    "    if len(pcl_list) == 3: break\n",
    "\n",
    "\n",
    "    # scan_list[0][0]['lidar']\n",
    "\n",
    "# visualize_points3D(pc1, pc1[:,3] == 0, lookat=[0,0,0])\n",
    "pc = np.concatenate(pcl_list)\n",
    "gl = np.concatenate(global_list)\n",
    "\n",
    "# visualize_points3D(pc, pc[:,5], lookat=[0,0,0])\n",
    "# visualize_points3D(gl, gl[:,2], lookat=[0,0,0])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T11:51:09.640446299Z",
     "start_time": "2023-08-28T11:51:09.529406590Z"
    }
   },
   "id": "2cc7386ea3b651fc"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "# pc to voxel grid\n",
    "voxel_size = 0.2\n",
    "max_x = 35\n",
    "max_y = 35\n",
    "max_z = 3\n",
    "min_x = -35\n",
    "min_y = -35\n",
    "min_z = -3\n",
    "\n",
    "\n",
    "voxel_grid = np.zeros((int((max_x - min_x) / voxel_size) + 2, int((max_y - min_y) / voxel_size) + 2, int((max_z - min_z) / voxel_size) + 2))\n",
    "all_time_voxel = voxel_grid.copy()\n",
    "\n",
    "for t in np.unique(pc[:,3]):\n",
    "    pc_in_range = pc[(pc[:,0] > min_x) & (pc[:,0] < max_x) & (pc[:,1] > min_y) & (pc[:,1] < max_y) & (pc[:,2] > min_z) & (pc[:,2] < max_z) & (pc[:,3] == t)]\n",
    "    pc_xyz = (pc_in_range[:,:3] - np.array([min_x, min_y, min_z])) / voxel_size\n",
    "    \n",
    "    voxel_grid = np.zeros((int((max_x - min_x) / voxel_size) + 2, int((max_y - min_y) / voxel_size) + 2, int((max_z - min_z) / voxel_size) + 2))\n",
    "    voxel_grid[pc_xyz[:,0].astype(int), pc_xyz[:,1].astype(int), pc_xyz[:,2].astype(int)] = 1\n",
    "    all_time_voxel += voxel_grid\n",
    "\n",
    "# color\n",
    "all_time_voxel = all_time_voxel.astype(int)\n",
    "pc_in_range = pc[(pc[:,0] > min_x) & (pc[:,0] < max_x) & (pc[:,1] > min_y) & (pc[:,1] < max_y) & (pc[:,2] > min_z) & (pc[:,2] < max_z)]\n",
    "pc_xyz = (pc_in_range[:,:3] - np.array([min_x, min_y, min_z])) / voxel_size\n",
    "accum_time_feature = all_time_voxel[pc_xyz[:,0].astype(int), pc_xyz[:,1].astype(int), pc_xyz[:,2].astype(int)]\n",
    "\n",
    "visualize_points3D(pc_in_range, accum_time_feature, lookat=[0,0,0])\n",
    "visualize_points3D(pc_in_range, pc_in_range[:, 3], lookat=[0,0,0])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T11:46:55.813651850Z",
     "start_time": "2023-08-28T11:46:55.718957739Z"
    }
   },
   "id": "d21601c98bef92dc"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import os \n",
    "import torch\n",
    "from vis.deprecated_vis import *\n",
    "# argoverse\n",
    "def find_robust_weighted_rigid_alignment(A, B, weights, use_epsilon_on_weights=False):\n",
    "    \"\"\"\n",
    "    Calculates the weighted rigid transformation that aligns two sets of points.\n",
    "    Args:\n",
    "        A (torch.Tensor): A tensor of shape (batch_size, num_points, 3) containing the first set of points.\n",
    "        B (torch.Tensor): A tensor of shape (batch_size, num_points, 3) containing the second set of points.\n",
    "        weights (torch.Tensor): A tensor of shaep (batch_size, num_points) containing weights.\n",
    "        use_epsilon_on_weights (bool): A condition if to use eps for weights.\n",
    "    Returns:\n",
    "        torch.Tensor: A tensor of shape (batch_size, 4, 4) containing the rigid transformation matrix that aligns A to B.\n",
    "    \"\"\"\n",
    "    # assert (weights >= 0.0).all(), \"Negative weights found\"\n",
    "    # if use_epsilon_on_weights:\n",
    "    #     weights += torch.finfo(weights.dtype).eps\n",
    "    #     count_nonzero_weighted_points = torch.sum(weights > 0.0, dim=-1)\n",
    "    #     not_enough_points = count_nonzero_weighted_points < 3\n",
    "    # else:\n",
    "    #     # Add eps if not enough points with weight over zero\n",
    "    #     count_nonzero_weighted_points = torch.sum(weights > 0.0, dim=-1)\n",
    "    #     not_enough_points = count_nonzero_weighted_points < 3\n",
    "    #     eps = not_enough_points.float() * torch.finfo(weights.dtype).eps\n",
    "    #     weights += eps.unsqueeze(-1)\n",
    "    # assert not not_enough_points, f\"pcl0 shape {A.shape}, pcl1 shape {B.shape}, points {count_nonzero_weighted_points}\"\n",
    "\n",
    "    weights = weights.unsqueeze(-1)\n",
    "    sum_weights = torch.sum(weights, dim=1)\n",
    "\n",
    "    A_weighted = A * weights\n",
    "    B_weighted = B * weights\n",
    "\n",
    "    a_mean = A_weighted.sum(axis=1) / sum_weights.unsqueeze(-1)\n",
    "    b_mean = B_weighted.sum(axis=1) / sum_weights.unsqueeze(-1)\n",
    "\n",
    "    A_c = A - a_mean\n",
    "    B_c = B - b_mean\n",
    "    # Covariance matrix\n",
    "    H = ((A_c * weights).transpose(1, 2) @ B_c) / sum_weights\n",
    "    U, S, V = torch.svd(H)\n",
    "    # Rotation matrix\n",
    "    R = V @ U.transpose(1, 2)\n",
    "    # Translation vector\n",
    "    t = b_mean.transpose(1, 2) - (R @ a_mean.transpose(1, 2))\n",
    "\n",
    "    T = torch.cat((R, t), dim=2)\n",
    "    T = torch.cat((T, torch.tensor([[[0,0,0,1]]], device=A.device)), dim=1)\n",
    "    return T\n",
    "\n",
    "def transform_pc(pts, pose):\n",
    "\n",
    "    '''\n",
    "\n",
    "    :param pts: point cloud\n",
    "    :param pose: 4x4 transformation matrix\n",
    "    :return:\n",
    "    '''\n",
    "    transformed_pts = np.insert(pts.copy(), 3, 1, axis=1)\n",
    "    transformed_pts[:, 3] = 1\n",
    "    transformed_pts[:, :3] = (transformed_pts[:, :4] @ pose.T)[:, :3]\n",
    "\n",
    "    return transformed_pts\n",
    "\n",
    "\n",
    "paths = sorted(glob.glob(f'{os.path.expanduser(\"~\")}/data/sceneflow/argoverse/val/f9*/*.npz'))[0]\n",
    "# paths = sorted(glob.glob(f'{os.path.expanduser(\"~\")}/data/sceneflow/kittisf/all_data_format/*.npz'))[0]\n",
    "pc_list = []\n",
    "data = np.load(paths, allow_pickle=True)\n",
    "pc1 = torch.from_numpy(data['pc1'])[None, :]\n",
    "pc2 = torch.from_numpy(data['pc2'])[None, :]\n",
    "flow = torch.from_numpy(data['flow'])[None, :]\n",
    "\n",
    "background_weights = torch.ones(flow.shape[:2])\n",
    "# background_weights = torch.from_numpy(data['inst_pc1'] == 0).to(torch.float)[None, :]\n",
    "\n",
    "pose = find_robust_weighted_rigid_alignment(pc1, pc1 + flow, weights=background_weights)\n",
    "\n",
    "global_pc = transform_pc(pc1[0].clone().numpy(), pose[0].numpy())\n",
    "# global_pc = pc1[0].numpy() - pose[0].numpy()[:3, 3]\n",
    "\n",
    "visualize_multiple_pcls(*[pc1[0].numpy(), global_pc[:,:3], pc2[0].numpy()], lookat=[0,0,0])\n",
    "# visualize_multiple_pcls(*[pc1[0].numpy() + flow[0].numpy(), pc2[0].numpy()], lookat=[0,0,0])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T11:53:37.430195Z",
     "start_time": "2023-08-28T11:53:37.387070821Z"
    }
   },
   "id": "e2d3b7e69c47f08a"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "ids = np.arange(10)\n",
    "probs = np.zeros((ids.shape[0], ids.max()))\n",
    "for i in range(ids.max()):\n",
    "    probs[ids == i, i] = 1\n",
    "print(probs)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T12:30:55.824932330Z",
     "start_time": "2023-08-28T12:30:55.764493287Z"
    }
   },
   "id": "2940879c43c58ec4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
