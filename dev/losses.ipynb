{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Title\n",
    "- When you feel you need to use function in general, then there is a natural barier here and you should write it into script and import it\n",
    "\n",
    "<!--- ![alt text](/home/patrik/pcflow/drawio/images/code.drawio.png) -->\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "/home.dokt/vacekpa2/.local/lib/python3.10/site-packages/FastGeodisCpp.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN3c104cuda20CUDACachingAllocator9allocatorE",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [2], line 7\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mglob\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mPATHS\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DATA_PATH, TMP_VIS_PATH\n\u001B[0;32m----> 7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mloss\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mflow\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01margparse\u001B[39;00m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mloss\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mflow\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m chamfer_distance_loss\n",
      "File \u001B[0;32m~/pcflow/loss/flow.py:8\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpytorch3d\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mknn\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m knn_points\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpytorch3d\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpoints_normals\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m estimate_pointcloud_normals\n\u001B[0;32m----> 8\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mFastGeodis\u001B[39;00m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mvisibility\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m KNN_visibility_solver, substitute_NN_by_mask, strip_KNN_with_vis\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mchamfer_distance_loss\u001B[39m(x, y, x_lengths\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, y_lengths\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, both_ways\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, normals_K\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, loss_norm\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m):\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/FastGeodis/__init__.py:33\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtyping\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m List\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[0;32m---> 33\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mFastGeodisCpp\u001B[39;00m\n\u001B[1;32m     36\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgeneralised_geodesic2d\u001B[39m(\n\u001B[1;32m     37\u001B[0m     image: torch\u001B[38;5;241m.\u001B[39mTensor, \n\u001B[1;32m     38\u001B[0m     softmask: torch\u001B[38;5;241m.\u001B[39mTensor, \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     41\u001B[0m     \u001B[38;5;28miter\u001B[39m: \u001B[38;5;28mint\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m2\u001B[39m\n\u001B[1;32m     42\u001B[0m ):\n\u001B[1;32m     43\u001B[0m     \u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Computes Generalised Geodesic Distance using FastGeodis raster scanning.\u001B[39;00m\n\u001B[1;32m     44\u001B[0m \u001B[38;5;124;03m    For more details on generalised geodesic distance, check the following reference:\u001B[39;00m\n\u001B[1;32m     45\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     60\u001B[0m \u001B[38;5;124;03m        torch.Tensor with distance transform\u001B[39;00m\n\u001B[1;32m     61\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n",
      "\u001B[0;31mImportError\u001B[0m: /home.dokt/vacekpa2/.local/lib/python3.10/site-packages/FastGeodisCpp.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN3c104cuda20CUDACachingAllocator9allocatorE"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from vis.deprecated_vis import *\n",
    "import glob\n",
    "from data.PATHS import DATA_PATH, TMP_VIS_PATH\n",
    "from loss.flow import *\n",
    "\n",
    "import argparse\n",
    "from loss.flow import chamfer_distance_loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-14T13:13:01.666956047Z",
     "start_time": "2023-06-14T13:13:01.389205412Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Structure Loss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Use Case for NN Flow\n",
    "Argoverse1 NSF - frame 2\n",
    "<img src=\"/home/patrik/pcflow/use_cases/Smooth_NN_from_flow.png\" width=600>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from data.PATHS import TMP_VIS_PATH\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "#\n",
    "# color = cm.viridis(est_flow.norm(dim\n",
    "#                                  =-1).detach().numpy()[0])\n",
    "#\n",
    "# plt.close()\n",
    "# fig, axes = plt.subplots(1,2, figsize=(10,5))\n",
    "# axes[0].plot(init_flow[0,:,0].detach(), init_flow[0,:,1].detach(), 'bo')\n",
    "# axes[0].plot(pc2[0,:,0].detach(), pc2[0,:,1].detach(), 'ro')\n",
    "#\n",
    "# s = axes[1].scatter(est_flow[0,:,0].detach(), est_flow[0,:,1].detach(), c=per_point_f_loss.detach(), cmap=cm.viridis)\n",
    "#\n",
    "# cb = plt.colorbar(mappable=s, ax=axes[1])\n",
    "# cb.set_label('Cbar Label Here')\n",
    "#\n",
    "# # axes[1].grid(True, which='both', axis='x', linewidth=1)\n",
    "# plt.savefig(TMP_VIS_PATH + 'scatter.png')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T09:25:38.822433598Z",
     "start_time": "2023-06-13T09:25:38.815171014Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "\n",
    "# transfer args to pandas, to csv and back\n",
    "\n",
    "import pandas as pd\n",
    "args_list = [args, args]\n",
    "values_list = []\n",
    "names = [n[0] for n in args_list[0]._get_kwargs()]\n",
    "\n",
    "for args in args_list:\n",
    "    values = [n[1] for n in args._get_kwargs()]\n",
    "    values_array = np.array((values))[None,:]\n",
    "    values_list.append(values_array)\n",
    "\n",
    "values_array = np.concatenate(values_list)\n",
    "\n",
    "df = pd.DataFrame(values_array, columns=names, index=None)\n",
    "df.to_csv('tst.csv')\n",
    "# rewrite manually?"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-12T13:58:46.923033511Z",
     "start_time": "2023-06-12T13:58:46.722484779Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Full loss example with animation\n",
    "- write example points for use case [x]\n",
    "- set up the losses for optimization of flow [x]\n",
    "- store iterations in video []\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[0.0885, 0.0470, 0.0864],\n         [0.0093, 0.0260, 0.0055],\n         [0.0175, 0.0089, 0.0111]]], requires_grad=True)"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example points\n",
    "pc1 = torch.tensor(((1.0,1,0), (1.3,1,0), (2.2,1,0))).unsqueeze(0)\n",
    "pc2 = torch.tensor(((1.0,0.5,0), (1.8,0.6,0), (1.5, 0.4,0))).unsqueeze(0)\n",
    "est_flow = torch.rand(pc1.shape) * 0.1\n",
    "# est_flow = torch.ones_like(pc1, requires_grad=True)\n",
    "# est_flow.retain_grad()\n",
    "est_flow.requires_grad_()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T11:02:31.028413008Z",
     "start_time": "2023-06-13T11:02:30.984256893Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "plt.close()\n",
    "plt.plot(pc1[0,:,0], pc1[0,:,1], 'bo')\n",
    "plt.plot(pc2[0,:,0], pc2[0,:,1], 'ro')\n",
    "plt.quiver(pc1[0,:,0], pc1[0,:,1], est_flow[0,:,0].detach(), est_flow[0,:,1].detach(), scale_units='xy',scale=1, color='g')\n",
    "\n",
    "plt.axis('equal')\n",
    "\n",
    "plt.savefig(TMP_VIS_PATH + 'points.png')\n",
    "\n",
    "\n",
    "def store_toy_iter(pc1, pc2, est_flow, e):\n",
    "\n",
    "    plt.close()\n",
    "    plt.plot(pc1[0,:,0], pc1[0,:,1], 'bo')\n",
    "    plt.plot(pc2[0,:,0], pc2[0,:,1], 'ro')\n",
    "    plt.quiver(pc1[0,:,0], pc1[0,:,1], est_flow[0,:,0].detach(), est_flow[0,:,1].detach(), scale_units='xy', color='g', scale=1)\n",
    "\n",
    "    plt.axis('equal')\n",
    "\n",
    "    plt.savefig(TMP_VIS_PATH + f'video/{e:04d}_points.png')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T11:25:02.559773952Z",
     "start_time": "2023-06-13T11:25:02.426539223Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "outputs": [],
   "source": [
    "# 2) smoothness propagation\n",
    "# K_SM = 3\n",
    "# _, NN_pc2, _ = knn_points(pc2, pc2, lengths1=None, lengths2=None, K=K_SM, norm=1)\n",
    "#\n",
    "# keep_ind = ind[ind[:,0] != pc2.shape[1] ,0]\n",
    "#\n",
    "# # print(\"\\n\\n Indices of pc2 for choosing only connections from NN(pc2) that has forward flow corespondences\\n\\n\", keep_ind)\n",
    "#\n",
    "#\n",
    "# # print(\"\\n\\n NN of pc2 that has correspondeces from flow\\n\\n\", NN_pc2[0, keep_ind, :])\n",
    "#\n",
    "# # znamena, ze est flow body maji tyhle indexy pro body v pc2 a ty indexy maji mit stejne flow.\n",
    "# n = NN_pc2[0, keep_ind, :]\n",
    "#\n",
    "# # beware of zeros\n",
    "# connected_flow = vec[n] # N x KSmooth x 3 (fx, fy, fz)\n",
    "# # print(connected_flow)\n",
    "#\n",
    "# # print(est_flow)\n",
    "# prep_flow = est_flow[0].unsqueeze(1).repeat_interleave(repeats=K_SM, dim=1)\n",
    "#\n",
    "# # smooth it, should be fine\n",
    "# flow_comparison = prep_flow - connected_flow\n",
    "#\n",
    "# # print(flow_comparison.shape)\n",
    "# # print(flow_comparison)\n",
    "# per_point_loss = flow_comparison.norm(dim=2).mean(dim=1)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-12T15:24:01.147764462Z",
     "start_time": "2023-06-12T15:24:01.131459675Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8017, grad_fn=<AddBackward0>)\n",
      "tensor(0.7223, grad_fn=<AddBackward0>)\n",
      "tensor(0.6569, grad_fn=<AddBackward0>)\n",
      "tensor(0.6335, grad_fn=<AddBackward0>)\n",
      "tensor(0.5929, grad_fn=<AddBackward0>)\n",
      "tensor(0.5606, grad_fn=<AddBackward0>)\n",
      "tensor(0.5279, grad_fn=<AddBackward0>)\n",
      "tensor(0.4982, grad_fn=<AddBackward0>)\n",
      "tensor(0.4540, grad_fn=<AddBackward0>)\n",
      "tensor(0.4350, grad_fn=<AddBackward0>)\n",
      "tensor(0.3837, grad_fn=<AddBackward0>)\n",
      "tensor(0.3691, grad_fn=<AddBackward0>)\n",
      "tensor(0.3210, grad_fn=<AddBackward0>)\n",
      "tensor(0.3022, grad_fn=<AddBackward0>)\n",
      "tensor(0.2843, grad_fn=<AddBackward0>)\n",
      "tensor(0.2650, grad_fn=<AddBackward0>)\n",
      "tensor(0.2479, grad_fn=<AddBackward0>)\n",
      "tensor(0.2622, grad_fn=<AddBackward0>)\n",
      "tensor(0.2455, grad_fn=<AddBackward0>)\n",
      "tensor(0.2555, grad_fn=<AddBackward0>)\n",
      "tensor(0.2409, grad_fn=<AddBackward0>)\n",
      "tensor(0.2539, grad_fn=<AddBackward0>)\n",
      "tensor(0.2415, grad_fn=<AddBackward0>)\n",
      "tensor(0.2590, grad_fn=<AddBackward0>)\n",
      "tensor(0.2428, grad_fn=<AddBackward0>)\n",
      "tensor(0.2532, grad_fn=<AddBackward0>)\n",
      "tensor(0.2423, grad_fn=<AddBackward0>)\n",
      "tensor(0.2534, grad_fn=<AddBackward0>)\n",
      "tensor(0.2411, grad_fn=<AddBackward0>)\n",
      "tensor(0.2562, grad_fn=<AddBackward0>)\n",
      "tensor(0.2385, grad_fn=<AddBackward0>)\n",
      "tensor(0.2560, grad_fn=<AddBackward0>)\n",
      "tensor(0.2369, grad_fn=<AddBackward0>)\n",
      "tensor(0.2562, grad_fn=<AddBackward0>)\n",
      "tensor(0.2385, grad_fn=<AddBackward0>)\n",
      "tensor(0.2532, grad_fn=<AddBackward0>)\n",
      "tensor(0.2438, grad_fn=<AddBackward0>)\n",
      "tensor(0.2542, grad_fn=<AddBackward0>)\n",
      "tensor(0.2489, grad_fn=<AddBackward0>)\n",
      "tensor(0.2459, grad_fn=<AddBackward0>)\n",
      "tensor(0.2507, grad_fn=<AddBackward0>)\n",
      "tensor(0.2430, grad_fn=<AddBackward0>)\n",
      "tensor(0.2509, grad_fn=<AddBackward0>)\n",
      "tensor(0.2465, grad_fn=<AddBackward0>)\n",
      "tensor(0.2457, grad_fn=<AddBackward0>)\n",
      "tensor(0.2492, grad_fn=<AddBackward0>)\n",
      "tensor(0.2421, grad_fn=<AddBackward0>)\n",
      "tensor(0.2513, grad_fn=<AddBackward0>)\n",
      "tensor(0.2420, grad_fn=<AddBackward0>)\n",
      "tensor(0.2500, grad_fn=<AddBackward0>)\n",
      "tensor(0.2462, grad_fn=<AddBackward0>)\n",
      "tensor(0.2519, grad_fn=<AddBackward0>)\n",
      "tensor(0.2508, grad_fn=<AddBackward0>)\n",
      "tensor(0.2443, grad_fn=<AddBackward0>)\n",
      "tensor(0.2521, grad_fn=<AddBackward0>)\n",
      "tensor(0.2416, grad_fn=<AddBackward0>)\n",
      "tensor(0.2521, grad_fn=<AddBackward0>)\n",
      "tensor(0.2455, grad_fn=<AddBackward0>)\n",
      "tensor(0.2465, grad_fn=<AddBackward0>)\n",
      "tensor(0.2485, grad_fn=<AddBackward0>)\n",
      "tensor(0.2428, grad_fn=<AddBackward0>)\n",
      "tensor(0.2508, grad_fn=<AddBackward0>)\n",
      "tensor(0.2424, grad_fn=<AddBackward0>)\n",
      "tensor(0.2497, grad_fn=<AddBackward0>)\n",
      "tensor(0.2465, grad_fn=<AddBackward0>)\n",
      "tensor(0.2517, grad_fn=<AddBackward0>)\n",
      "tensor(0.2511, grad_fn=<AddBackward0>)\n",
      "tensor(0.2441, grad_fn=<AddBackward0>)\n",
      "tensor(0.2523, grad_fn=<AddBackward0>)\n",
      "tensor(0.2415, grad_fn=<AddBackward0>)\n",
      "tensor(0.2523, grad_fn=<AddBackward0>)\n",
      "tensor(0.2454, grad_fn=<AddBackward0>)\n",
      "tensor(0.2466, grad_fn=<AddBackward0>)\n",
      "tensor(0.2484, grad_fn=<AddBackward0>)\n",
      "tensor(0.2429, grad_fn=<AddBackward0>)\n",
      "tensor(0.2507, grad_fn=<AddBackward0>)\n",
      "tensor(0.2425, grad_fn=<AddBackward0>)\n",
      "tensor(0.2496, grad_fn=<AddBackward0>)\n",
      "tensor(0.2465, grad_fn=<AddBackward0>)\n",
      "tensor(0.2517, grad_fn=<AddBackward0>)\n",
      "tensor(0.2511, grad_fn=<AddBackward0>)\n",
      "tensor(0.2440, grad_fn=<AddBackward0>)\n",
      "tensor(0.2523, grad_fn=<AddBackward0>)\n",
      "tensor(0.2414, grad_fn=<AddBackward0>)\n",
      "tensor(0.2523, grad_fn=<AddBackward0>)\n",
      "tensor(0.2454, grad_fn=<AddBackward0>)\n",
      "tensor(0.2467, grad_fn=<AddBackward0>)\n",
      "tensor(0.2484, grad_fn=<AddBackward0>)\n",
      "tensor(0.2429, grad_fn=<AddBackward0>)\n",
      "tensor(0.2507, grad_fn=<AddBackward0>)\n",
      "tensor(0.2425, grad_fn=<AddBackward0>)\n",
      "tensor(0.2496, grad_fn=<AddBackward0>)\n",
      "tensor(0.2465, grad_fn=<AddBackward0>)\n",
      "tensor(0.2516, grad_fn=<AddBackward0>)\n",
      "tensor(0.2511, grad_fn=<AddBackward0>)\n",
      "tensor(0.2440, grad_fn=<AddBackward0>)\n",
      "tensor(0.2523, grad_fn=<AddBackward0>)\n",
      "tensor(0.2414, grad_fn=<AddBackward0>)\n",
      "tensor(0.2523, grad_fn=<AddBackward0>)\n",
      "tensor(0.2454, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# optimize  # add rigid kabsch to regularizer of NN?\n",
    "# smoothness with option of pc2 smoothness\n",
    "K_SM = 2\n",
    "optimizer = torch.optim.SGD([est_flow], lr=0.1)\n",
    "_, NN_pc2, _ = knn_points(pc2, pc2, lengths1=None, lengths2=None, K=K_SM, norm=1)\n",
    "\n",
    "\n",
    "\n",
    "for e in range(100):\n",
    "\n",
    "    _, forward_nn, _ = knn_points(pc1 + est_flow, pc2, lengths1=None, lengths2=None, K=1, norm=1)\n",
    "\n",
    "    a = est_flow[0] # magnitude\n",
    "\n",
    "    ind = forward_nn[0] # more than one?\n",
    "\n",
    "    #if pc1 is bigger than pc2, then skip?\n",
    "    if pc1.shape[1] < pc2.shape[1]:\n",
    "        shape_diff = pc2.shape[1] - ind.shape[0] + 1 # one for dummy    # what if pc1 is bigger than pc2?\n",
    "        a = F.pad(a, (0,0,0, shape_diff), mode='constant', value=0)\n",
    "        a.retain_grad() # padding does not retain grad, need to do it manually. Check it\n",
    "\n",
    "        ind = F.pad(ind, (0,0,0, shape_diff), mode='constant', value=pc2.shape[1])  # pad with dummy not in orig\n",
    "\n",
    "    # storage of same points\n",
    "    vec = torch.zeros(ind.shape[0], 3)\n",
    "\n",
    "    vec = vec.scatter_reduce_(0, ind.repeat(1,3), a, reduce='mean', include_self=False)  # will do forward flow\n",
    "\n",
    "    # rest is pc2 smoothness with pre-computed NN\n",
    "    keep_ind = ind[ind[:,0] != pc2.shape[1] ,0]\n",
    "\n",
    "    # znamena, ze est flow body maji tyhle indexy pro body v pc2 a ty indexy maji mit stejne flow.\n",
    "    n = NN_pc2[0, keep_ind, :]\n",
    "\n",
    "    # beware of zeros!!!\n",
    "    connected_flow = vec[n] # N x KSmooth x 3 (fx, fy, fz)\n",
    "\n",
    "    prep_flow = est_flow[0].unsqueeze(1).repeat_interleave(repeats=K_SM, dim=1) # correct\n",
    "\n",
    "    # smooth it, should be fine\n",
    "    flow_diff = prep_flow - connected_flow  # correct operation, but zeros makes problem\n",
    "\n",
    "    occupied_mask = connected_flow.all(dim=2).repeat(3,1,1).permute(1,2,0)\n",
    "\n",
    "    # occupied_mask\n",
    "    per_flow_dim_diff = torch.masked_select(flow_diff, occupied_mask)\n",
    "\n",
    "    # per_point_loss = per_flow_dim_diff.norm(dim=-1).mean()\n",
    "    per_point_loss = (per_flow_dim_diff ** 2).mean()    # powered to 2 because norm will sum it directly\n",
    "\n",
    "    chamf_loss, _, _ = chamfer_distance_loss(pc1 + est_flow, pc2, both_ways=False)\n",
    "\n",
    "    loss = 10. * per_point_loss.mean() + chamf_loss\n",
    "    # loss = chamf_loss\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    store_toy_iter(pc1.detach(), pc2.detach(), est_flow.detach(), e)\n",
    "\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    print(loss)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T11:02:42.114358527Z",
     "start_time": "2023-06-13T11:02:34.284652764Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "# optimize  # add rigid kabsch to regularizer of NN?\n",
    "# smoothness with option of pc2 smoothness\n",
    "\n",
    "def forward_smoothness(pc1, pc2, est_flow, NN_pc2=None, K_SM=2, include_pc2_smoothness=True):\n",
    "\n",
    "    if NN_pc2 is None and include_pc2_smoothness:\n",
    "        # Compute NN_pc2\n",
    "        _, NN_pc2, _ = knn_points(pc2, pc2, lengths1=None, lengths2=None, K=K_SM, norm=1)\n",
    "\n",
    "\n",
    "    _, forward_nn, _ = knn_points(pc1 + est_flow, pc2, lengths1=None, lengths2=None, K=1, norm=1)\n",
    "\n",
    "    a = est_flow[0] # magnitude\n",
    "\n",
    "    ind = forward_nn[0] # more than one?\n",
    "\n",
    "    if pc1.shape[1] < pc2.shape[1]:\n",
    "        shape_diff = pc2.shape[1] - ind.shape[0] + 1 # one for dummy    # what if pc1 is bigger than pc2?\n",
    "        a = F.pad(a, (0,0,0, shape_diff), mode='constant', value=0)\n",
    "        a.retain_grad() # padding does not retain grad, need to do it manually. Check it\n",
    "\n",
    "        ind = F.pad(ind, (0,0,0, shape_diff), mode='constant', value=pc2.shape[1])  # pad with dummy not in orig\n",
    "\n",
    "    # storage of same points\n",
    "    vec = torch.zeros(ind.shape[0], 3)\n",
    "\n",
    "    # this is forward flow withnout NN_pc2 smoothness\n",
    "    vec = vec.scatter_reduce_(0, ind.repeat(1,3), a, reduce='mean', include_self=False)\n",
    "\n",
    "    forward_flow_loss = torch.nn.functional.mse_loss(vec[ind[:,0]], a, reduction='none').mean(dim=-1)\n",
    "\n",
    "    if include_pc2_smoothness:\n",
    "        # rest is pc2 smoothness with pre-computed NN\n",
    "        keep_ind = ind[ind[:,0] != pc2.shape[1] ,0]\n",
    "\n",
    "        # znamena, ze est flow body maji tyhle indexy pro body v pc2 a ty indexy maji mit stejne flow.\n",
    "        n = NN_pc2[0, keep_ind, :]\n",
    "\n",
    "        # beware of zeros!!!\n",
    "        connected_flow = vec[n] # N x KSmooth x 3 (fx, fy, fz)\n",
    "\n",
    "        prep_flow = est_flow[0].unsqueeze(1).repeat_interleave(repeats=K_SM, dim=1) # correct\n",
    "\n",
    "        # smooth it, should be fine\n",
    "        flow_diff = prep_flow - connected_flow  # correct operation, but zeros makes problem\n",
    "\n",
    "        occupied_mask = connected_flow.all(dim=2).repeat(3,1,1).permute(1,2,0)\n",
    "\n",
    "        # occupied_mask\n",
    "        per_flow_dim_diff = torch.masked_select(flow_diff, occupied_mask)\n",
    "\n",
    "        # per_point_loss = per_flow_dim_diff.norm(dim=-1).mean()\n",
    "        NN_pc2_loss = (per_flow_dim_diff ** 2).mean()    # powered to 2 because norm will sum it directly\n",
    "\n",
    "    else:\n",
    "        NN_pc2_loss = torch.tensor(0.)\n",
    "\n",
    "    return forward_flow_loss.mean(), forward_flow_loss, NN_pc2_loss\n",
    "\n",
    "\n",
    "# asi good\n",
    "\n",
    "# todo visualize connections of NN"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T11:24:53.017453905Z",
     "start_time": "2023-06-13T11:24:52.971693785Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0],\n",
      "        [2],\n",
      "        [1]])\n"
     ]
    },
    {
     "data": {
      "text/plain": "(tensor(0., grad_fn=<MeanBackward0>),\n tensor([0., 0., 0.], grad_fn=<MeanBackward1>),\n tensor(0.0048, grad_fn=<MeanBackward0>))"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward_smoothness(pc1, pc2, est_flow, NN_pc2=None, K_SM=2, include_pc2_smoothness=True)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T11:25:47.144014701Z",
     "start_time": "2023-06-13T11:25:47.097476789Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
