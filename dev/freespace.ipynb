{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Freespace\n",
    "- import data [x]\n",
    "- set up representation yaw, pitch, depth [x]\n",
    "- solver resolution - nearby points creates boundary? [x]\n",
    "- visualize on example [x]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from vis.deprecated_vis import *\n",
    "from data.PATHS import TMP_VIS_PATH\n",
    "from data.NSF_data import NSF_dataset\n",
    "from data.range_image import range_image_coords, create_depth_img\n",
    "\n",
    "dataset = NSF_dataset()\n",
    "data = next(dataset.__iter__())\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "pc1, pc2, gt_flow = data\n",
    "\n",
    "pc1 = pc1.to(device)\n",
    "pc2 = pc2.to(device)\n",
    "gt_flow = gt_flow.to(device)\n",
    "est_flow = torch.randn(pc1.shape, device=device, requires_grad=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T09:30:01.463619027Z",
     "start_time": "2023-06-29T09:30:01.402306452Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "from pytorch3d.ops.knn import knn_points\n",
    "\n",
    "def calculate_polar_coords(pc):\n",
    "\n",
    "    calc_depth = torch.norm(pc[:,:3], dim=1)\n",
    "    yaw = - torch.arctan2(pc[:, 1], pc[:, 0])\n",
    "    pitch = torch.arcsin(pc[:, 2] / (calc_depth + 1e-8))\n",
    "\n",
    "    return yaw, pitch, calc_depth\n",
    "\n",
    "\n",
    "def yaw_pitch_depth_to_xyz(yaw, pitch, depth):\n",
    "    # generated, maybe shifted\n",
    "    # Convert degrees to radians\n",
    "    # yaw = math.radians(yaw)\n",
    "    # pitch = math.radians(pitch)\n",
    "\n",
    "    # correct [x]\n",
    "    # Calculate XYZ coordinates\n",
    "    x = depth * torch.cos(yaw) * torch.cos(pitch)\n",
    "    y = depth * torch.sin(yaw) * torch.cos(pitch)\n",
    "    z = depth * torch.sin(pitch)\n",
    "\n",
    "    xyz = torch.stack([x, y, z]).T#[..., [2, 0, 1]]\n",
    "    xyz[:, 1] = - xyz[:, 1]\n",
    "\n",
    "    return xyz\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T09:30:01.510495117Z",
     "start_time": "2023-06-29T09:30:01.510069664Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Representation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create freespace label"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "t_z1 = 1.640420\n",
    "t_z2 = 1.565252\n",
    "t_z_mean = (t_z1 + t_z2) / 2\n",
    "# todo tohle asi zpusobuje error v rekonstrukci, dva body maji diky jinemu souradnemu systemu stejny pitch a yaw, a pak jsou za sebou a jeden ma depth malou a druhy velkou. proto se do point cloudu promitne jinak. - Ale proc range image je jiny, kdyz vstupy jsou stejne?!?\n",
    "\n",
    "# resolution based on the data?\n",
    "# todo pouzit puvodni point cloud []\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T09:30:01.512305335Z",
     "start_time": "2023-06-29T09:30:01.510719363Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "outputs": [],
   "source": [
    "\n",
    "class SmoothnessLoss(torch.nn.Module):\n",
    "\n",
    "#     # use normals to calculate smoothness loss\n",
    "    def __init__(self, pc1, pc2=None, K=12, sm_normals_K=0, smooth_weight=1., VA=False, max_radius=2, loss_norm=1, forward_weight=0., pc2_smooth=False, **kwargs):\n",
    "\n",
    "        super().__init__()\n",
    "        self.K = K\n",
    "        self.max_radius = max_radius\n",
    "        self.pc1 = pc1\n",
    "        self.pc2 = pc2\n",
    "        self.normals_K = sm_normals_K\n",
    "        self.loss_norm = loss_norm\n",
    "        self.smooth_weight = smooth_weight\n",
    "\n",
    "        # normal Smoothness\n",
    "        if self.normals_K > 3:\n",
    "            self.dist1, self.NN_pc1, _ = self.KNN_with_normals(pc1)\n",
    "        else:\n",
    "            self.dist1, self.NN_pc1, _ = knn_points(self.pc1, self.pc1, K=self.K)\n",
    "\n",
    "        self.NN_pc1 = mask_NN_by_dist(self.dist1, self.NN_pc1, max_radius)\n",
    "\n",
    "\n",
    "        # vis-aware - jenom skrtam, muze byt po radiusu\n",
    "        self.VA = VA\n",
    "        if VA:\n",
    "            # todo\n",
    "            pass\n",
    "        # ff\n",
    "        self.forward_weight = forward_weight\n",
    "\n",
    "        # ff with NNpc2\n",
    "        self.pc2_smooth = pc2_smooth\n",
    "        self.NN_pc2 = None\n",
    "\n",
    "        if pc2_smooth:\n",
    "\n",
    "            if self.normals_K > 3:\n",
    "                self.dist2, self.NN_pc2, _ = self.KNN_with_normals(pc2)\n",
    "            else:\n",
    "                self.dist2, self.NN_pc2, _ = knn_points(self.pc2, self.pc2, K=self.K)\n",
    "\n",
    "            self.NN_pc2 = mask_NN_by_dist(self.dist2, self.NN_pc2, max_radius)\n",
    "\n",
    "            if VA:\n",
    "                pass\n",
    "\n",
    "    def forward(self, pc1, est_flow, pc2):\n",
    "\n",
    "        loss = torch.tensor(0, dtype=torch.float32, device=pc1.device)\n",
    "\n",
    "        if self.smooth_weight > 0:\n",
    "            smooth_loss, pp_smooth_loss = self.smoothness_loss(est_flow, self.NN_pc1, self.loss_norm)\n",
    "\n",
    "            loss += self.smooth_weight * smooth_loss\n",
    "\n",
    "        if self.forward_weight > 0:\n",
    "            forward_loss, pp_forward_loss = self.forward_smoothness(pc1, est_flow, pc2)\n",
    "\n",
    "            loss += self.forward_weight * forward_loss\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def KNN_with_normals(self, pc):\n",
    "\n",
    "        normals = estimate_pointcloud_normals(pc, neighborhood_size=self.normals_K)\n",
    "        pc_with_norms = torch.cat([pc, normals], dim=-1)\n",
    "\n",
    "        return knn_points(pc_with_norms, pc_with_norms, K=self.K)\n",
    "\n",
    "    def smoothness_loss(self, est_flow, NN_idx, loss_norm=1, mask=None):\n",
    "\n",
    "        bs, n, c = est_flow.shape\n",
    "\n",
    "        if bs > 1:\n",
    "            print(\"Smoothness Maybe not working for bs>1, needs testing!\")\n",
    "        K = NN_idx.shape[2]\n",
    "\n",
    "        est_flow_neigh = est_flow.view(bs * n, c)\n",
    "        est_flow_neigh = est_flow_neigh[NN_idx.view(bs * n, K)]\n",
    "\n",
    "        est_flow_neigh = est_flow_neigh[:, 1:K + 1, :]\n",
    "        flow_diff = est_flow.view(bs * n, c) - est_flow_neigh.permute(1, 0, 2)\n",
    "\n",
    "        flow_diff = (flow_diff).norm(p=loss_norm, dim=2)\n",
    "        smooth_flow_loss = flow_diff.mean()\n",
    "        smooth_flow_per_point = flow_diff.mean(dim=0).view(bs, n)\n",
    "\n",
    "        return smooth_flow_loss, smooth_flow_per_point\n",
    "\n",
    "\n",
    "    def forward_smoothness(self, pc1, est_flow, pc2):\n",
    "\n",
    "\n",
    "        _, forward_nn, _ = knn_points(pc1 + est_flow, pc2, lengths1=None, lengths2=None, K=1, norm=1)\n",
    "\n",
    "        a = est_flow[0] # magnitude\n",
    "\n",
    "        ind = forward_nn[0] # more than one?\n",
    "\n",
    "        if pc1.shape[1] < pc2.shape[1]:\n",
    "            shape_diff = pc2.shape[1] - ind.shape[0] + 1 # one for dummy    # what if pc1 is bigger than pc2?\n",
    "            a = torch.nn.functional.pad(a, (0,0,0, shape_diff), mode='constant', value=0)\n",
    "            a.retain_grad() # padding does not retain grad, need to do it manually. Check it\n",
    "\n",
    "            ind = torch.nn.functional.pad(ind, (0,0,0, shape_diff), mode='constant', value=pc2.shape[1])  # pad with dummy not in orig\n",
    "\n",
    "        # storage of same points\n",
    "        vec = torch.zeros(ind.shape[0], 3, device=pc1.device)\n",
    "\n",
    "        # this is forward flow withnout NN_pc2 smoothness\n",
    "        vec = vec.scatter_reduce_(0, ind.repeat(1,3), a, reduce='mean', include_self=False)\n",
    "\n",
    "        forward_flow_loss = torch.nn.functional.mse_loss(vec[ind[:,0]], a, reduction='none').mean(dim=-1)\n",
    "\n",
    "        if self.pc2_smooth:\n",
    "            # rest is pc2 smoothness with pre-computed NN\n",
    "            keep_ind = ind[ind[:,0] != pc2.shape[1] ,0]\n",
    "\n",
    "            # znamena, ze est flow body maji tyhle indexy pro body v pc2 a ty indexy maji mit stejne flow.\n",
    "            n = self.NN_pc2[0, keep_ind, :]\n",
    "\n",
    "            # beware of zeros!!!\n",
    "            connected_flow = vec[n] # N x KSmooth x 3 (fx, fy, fz)\n",
    "\n",
    "            prep_flow = est_flow[0].unsqueeze(1).repeat_interleave(repeats=self.K, dim=1) # correct\n",
    "\n",
    "            # smooth it, should be fine\n",
    "            flow_diff = prep_flow - connected_flow  # correct operation, but zeros makes problem\n",
    "\n",
    "            occupied_mask = connected_flow.all(dim=2).repeat(3,1,1).permute(1,2,0)\n",
    "\n",
    "            # occupied_mask\n",
    "            per_flow_dim_diff = torch.masked_select(flow_diff, occupied_mask)\n",
    "\n",
    "            # per_point_loss = per_flow_dim_diff.norm(dim=-1).mean()\n",
    "            NN_pc2_loss = (per_flow_dim_diff ** 2).mean()    # powered to 2 because norm will sum it directly\n",
    "\n",
    "        else:\n",
    "            NN_pc2_loss = torch.tensor(0.)\n",
    "\n",
    "        forward_loss = forward_flow_loss.mean() + NN_pc2_loss\n",
    "\n",
    "        return forward_loss, forward_flow_loss\n",
    "\n",
    "class VAChamferLoss(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, pc2, fov_up, fov_down, proj_H, proj_W, max_range, nn_weight=1, nn_max_radius=5, both_ways=False, free_weight=0, margin=0.001, ch_normals_K=0, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.pc2 = pc2\n",
    "\n",
    "        # visibility component\n",
    "        # todo option of \"pushing\" points out of the freespace\n",
    "        self.free_weight = free_weight\n",
    "        self.fov_up = fov_up\n",
    "        self.fov_down = fov_down\n",
    "        self.proj_H = proj_H\n",
    "        self.proj_W = proj_W\n",
    "        self.max_range = max_range\n",
    "        self.margin = margin\n",
    "\n",
    "        # NN component\n",
    "        self.normals_K = ch_normals_K\n",
    "        self.nn_weight = nn_weight\n",
    "        self.nn_max_radius = nn_max_radius\n",
    "        self.both_ways = both_ways\n",
    "\n",
    "        torch.use_deterministic_algorithms(mode=True, warn_only=False)  # this ...\n",
    "        pc2_depth, idx_w, idx_h, inside_range_img = range_image_coords(pc2[0], fov_up, fov_down, proj_H, proj_W)\n",
    "        self.range_depth = create_depth_img(pc2_depth, idx_w, idx_h, proj_H, proj_W, inside_range_img)\n",
    "        torch.use_deterministic_algorithms(mode=False, warn_only=False)  # this ...\n",
    "\n",
    "    def forward(self, pc1, est_flow, pc2=None):\n",
    "        '''\n",
    "\n",
    "        Args:\n",
    "            pc1:\n",
    "            est_flow:\n",
    "\n",
    "        Returns:\n",
    "        mask whether the deformed point cloud is in freespace visibility area\n",
    "        '''\n",
    "        # dynamic\n",
    "\n",
    "        # assign Kabsch to lonely points or just push them out of freespace?\n",
    "        # precompute chamfer, radius\n",
    "        chamf_x, chamf_y = self.chamfer_distance_loss(pc1 + est_flow, self.pc2, both_ways=self.both_ways, normals_K=self.normals_K)\n",
    "\n",
    "        if self.free_weight > 0:\n",
    "            freespace_loss = self.flow_freespace_loss(pc1, est_flow, chamf_x)\n",
    "\n",
    "        else:\n",
    "            freespace_loss = torch.zeros_like(chamf_x, dtype=torch.float32, device=chamf_x.device)\n",
    "\n",
    "        chamf_loss = self.nn_weight * (chamf_x.mean() + chamf_y.mean()) + self.free_weight * freespace_loss.mean()\n",
    "\n",
    "        return chamf_loss, freespace_loss\n",
    "\n",
    "\n",
    "    def chamfer_distance_loss(self, x, y, x_lengths=None, y_lengths=None, both_ways=False, normals_K=0, loss_norm=1):\n",
    "        '''\n",
    "        Unique Nearest Neighboors?\n",
    "        :param x:\n",
    "        :param y:\n",
    "        :param x_lengths:\n",
    "        :param y_lengths:\n",
    "        :param reduction:\n",
    "        :return:\n",
    "        '''\n",
    "        if normals_K >= 3:\n",
    "            normals1 = estimate_pointcloud_normals(x, neighborhood_size=normals_K)\n",
    "            normals2 = estimate_pointcloud_normals(y, neighborhood_size=normals_K)\n",
    "\n",
    "            x = torch.cat([x, normals1], dim=-1)\n",
    "            y = torch.cat([y, normals2], dim=-1)\n",
    "\n",
    "\n",
    "        x_nn = knn_points(x, y, lengths1=x_lengths, lengths2=y_lengths, K=1, norm=loss_norm)\n",
    "        cham_x = x_nn.dists[..., 0]  # (N, P1)\n",
    "        # x_nearest_to_y = x_nn[1]\n",
    "\n",
    "        if both_ways:\n",
    "            y_nn = knn_points(y, x, lengths1=y_lengths, lengths2=x_lengths, K=1, norm=loss_norm)\n",
    "            cham_y = y_nn.dists[..., 0]  # (N, P2)\n",
    "            # y_nearest_to_x = y_nn[1]\n",
    "        else:\n",
    "\n",
    "            cham_y = torch.tensor(0, dtype=torch.float32, device=x.device)\n",
    "\n",
    "        return cham_x, cham_y\n",
    "\n",
    "    def flow_freespace_loss(self, pc1, est_flow, chamf_x):\n",
    "\n",
    "        flow_depth, flow_w, flow_h, flow_inside = range_image_coords((pc1 + est_flow)[0], self.fov_up, self.fov_down, self.proj_H, self.proj_W)\n",
    "\n",
    "            # use it only for flow inside the image\n",
    "        masked_pc2_depth = self.range_depth[flow_h[flow_inside], flow_w[flow_inside]]\n",
    "        compared_depth = masked_pc2_depth - flow_depth[flow_inside]\n",
    "\n",
    "        # compared_depth\n",
    "        # if flow point before the visible point from pc2, then it is in freespace\n",
    "        # margin is just little number to not push points already close to visible point\n",
    "        flow_in_freespace = compared_depth > 0 + self.margin\n",
    "\n",
    "\n",
    "        # Indexing flow in freespace\n",
    "        freespace_mask = torch.zeros_like(chamf_x, dtype=torch.bool)[0]\n",
    "        freespace_mask[flow_inside] = flow_in_freespace\n",
    "\n",
    "        # only pc1 NN\n",
    "        freespace_loss = freespace_mask * chamf_x\n",
    "\n",
    "        return freespace_loss\n",
    "\n",
    "\n",
    "class LossModule(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "\n",
    "    def update(self, pc1, pc2):\n",
    "\n",
    "        self.VAChamfer_loss = VAChamferLoss(pc2, **self.kwargs)\n",
    "        self.Smoothness_loss = SmoothnessLoss(pc1, pc2, **self.kwargs)\n",
    "\n",
    "    def forward(self, pc1, est_flow, pc2):\n",
    "\n",
    "        chamf_loss, pp_freespace_loss = self.VAChamfer_loss(pc1, est_flow)\n",
    "        smooth_loss = self.Smoothness_loss(pc1, est_flow, pc2)\n",
    "\n",
    "        loss = smooth_loss + chamf_loss\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "kwargs = {\n",
    "    'fov_up': fov_up,\n",
    "    'fov_down': fov_down,\n",
    "    'proj_H': proj_H,\n",
    "    'proj_W': proj_W,\n",
    "    'max_range': max_range,\n",
    "    'margin': 0.01,\n",
    "    'both_ways' : True,\n",
    "\n",
    "    # Smooth\n",
    "    'sm_normals_K' : 8,\n",
    "    'K': 5,\n",
    "    'forward_weight' : 1,\n",
    "    'smooth_weight' : 1,\n",
    "\n",
    "    # Chamfer\n",
    "    'free_weight' : 1,\n",
    "    'ch_normals_K' : 0,\n",
    "    'chamfer_weight' : 2,\n",
    "    'nn_max_radius' : 2,\n",
    "    'smoothness_weight' : 0.1,\n",
    "}\n",
    "\n",
    "loss_module = LossModule(**kwargs)\n",
    "loss_module.update(pc1, pc2)\n",
    "loss = loss_module(pc1, est_flow, pc2)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "# visualize_points3D(pc1[0], pp_freespace_loss[0])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fov_up': 'fov_up,', 'fov_down': 'fov_down,', 'proj_H': 'proj_H,', 'proj_W': 'proj_W,', 'max_range': 'max_range,', 'margin': '0.01,', 'both_ways': 'True,', 'sm_normals_K': '8,', 'K': '5,', 'forward_weight': '1,', 'smooth_weight': '1,', 'free_weight': '1,', 'ch_normals_K': '0,', 'nn_weights': '2,', 'nn_max_radius': '2,', 'smoothness_weight': '0.1,'}\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "with open('../configs/first.yml') as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "print(config['Loss'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T12:30:35.756588980Z",
     "start_time": "2023-06-29T12:30:35.705123900Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
